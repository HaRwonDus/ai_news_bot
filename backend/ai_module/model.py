import json
import re
from transformers import pipeline
from difflib import SequenceMatcher
from sqlalchemy import Column, Integer, String, Text, DateTime, func
from backend.db.database import Base

# --- üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ---
# –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ–º–µ—Ü–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

# –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏
translator_de_en = pipeline("translation", model="Helsinki-NLP/opus-mt-de-en")
translator_de_ru = pipeline(
    "translation",
    model="facebook/nllb-200-distilled-600M",
    src_lang="deu_Latn",
    tgt_lang="rus_Cyrl",
)

# --- üîπ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def clean_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def is_similar(a, b, threshold=0.75):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫ (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥—É–±–ª–µ–π)"""
    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold


def summarize_text_safe(
    text: str,
    max_chars: int = 1800,
    max_len: int = 80,
    min_len: int = 25,
):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ summarizer:
    - –æ–±—Ä–µ–∑–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
    - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
    - –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –æ—à–∏–±–æ–∫ huggingface
    """
    text = clean_text(text)
    if len(text) > max_chars:
        text = text[:max_chars]

    if len(text.split()) < 30:  # –º–µ–Ω—å—à–µ ~30 —Å–ª–æ–≤ ‚Äî —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
        return None

    try:
        out = summarizer(
            text,
            max_length=max_len,
            min_length=min_len,
            do_sample=False,
            truncation=True,
        )
        if not out or "summary_text" not in out[0]:
            return None
        return out[0]["summary_text"]
    except Exception:
        return None


# --- üîπ –ö–æ—Ä–æ—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (/news) ---
def summarize_news(news_json: str):
    """–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º (–¥–ª—è –∫–æ–º–∞–Ω–¥—ã /news)"""
    data = json.loads(news_json)
    summaries = []

    for n in data[:5]:
        title = n.get("title", "").strip()
        if not title:
            continue

        try:
            summary = summarizer(
                title, max_length=50, min_length=10, do_sample=False
            )[0]["summary_text"]
            summaries.append(f"üóûÔ∏è {summary}\nüîó {n.get('url', '')}")
        except Exception as e:
            summaries.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}\n{title}")

    if not summaries:
        return "‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."
    return "\n\n".join(summaries)


# --- üîπ –ì–ª—É–±–æ–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (/smartnews) ---
def smart_summarize(news_json: str):
    """–°–æ–∑–¥–∞—ë—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç–µ–π"""
    data = json.loads(news_json)
    clean_articles = []
    seen_titles = []

    for item in data:
        title = clean_text(item["title"])
        if any(is_similar(title, t) for t in seen_titles):
            continue
        seen_titles.append(title)

        content = clean_text(item.get("content", ""))
        if len(content) > 300:  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
            clean_articles.append({
                "title": title,
                "url": item["url"],
                "content": content
            })

    summaries = []

    for art in clean_articles[:5]:
        summary = summarize_text_safe(art["content"])
        if not summary:
            summaries.append(
                f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ –Ω–µ –ø–æ–¥–æ—à—ë–ª –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.\n{art['title']}"
            )
            continue

        summaries.append(f"üì∞ *{art['title']}*\n{summary}\nüîó {art['url']}")

    if not summaries:
        return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É. –í–æ–∑–º–æ–∂–Ω–æ, –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞."
    return "\n\n".join(summaries)


# --- üîπ –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è (/multilangnews) ---
def summarize_multilang(news_json: str):
    """–°–æ–∑–¥–∞—ë—Ç –≤—ã–∂–∏–º–∫—É –Ω–∞ 3 —è–∑—ã–∫–∞—Ö (DE, EN, RU)"""
    data = json.loads(news_json)
    results = []

    for n in data[:5]:
        content = clean_text(n["content"])
        if len(content) < 300:
            continue

        summary_de = summarize_text_safe(content)
        if not summary_de:
            continue

        try:
            summary_en = translator_de_en(summary_de)[0]["translation_text"]
            summary_ru = translator_de_ru(summary_de)[0]["translation_text"]

            block = (
                f"üì∞ *{n['title']}*\n\n"
                f"üá©üá™ **DE:** {summary_de}\n\n"
                f"üá¨üáß **EN:** {summary_en}\n\n"
                f"üá∑üá∫ **RU:** {summary_ru}\n\n"
                f"üîó {n['url']}"
            )
            results.append(block)
        except Exception as e:
            results.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏: {e}")

    if not results:
        return "‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞."
    return "\n\n".join(results)

